{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719b9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (1.44.1)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.29.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9104f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "import uuid\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "# 常數設定\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0438ce",
   "metadata": {},
   "source": [
    "### 簡單的模型選擇器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac7d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModelSelector:\n",
    "    \"\"\"簡單的模型選擇器\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 可選的 LLM 模型\n",
    "        self.llm_models = {\"openai\": \"GPT-4\", \"ollama\": \"Llama3\"}\n",
    "\n",
    "        # 可選的 Embedding 模型及其維度\n",
    "        self.embedding_models = {\n",
    "            \"openai\": {\"name\": \"OpenAI Embeddings\", \"dimensions\": 1536, \"model_name\": \"text-embedding-3-small\"},\n",
    "            \"chroma\": {\"name\": \"Chroma Default\", \"dimensions\": 384, \"model_name\": None},\n",
    "            \"nomic\": {\"name\": \"Nomic Embed Text\", \"dimensions\": 768, \"model_name\": \"nomic-embed-text\"},\n",
    "        }\n",
    "\n",
    "    def select_models(self):\n",
    "        \"\"\"透過 Streamlit 介面選擇模型\"\"\"\n",
    "        st.sidebar.title(\"📚 模型選擇\")\n",
    "\n",
    "        llm = st.sidebar.radio(\n",
    "            \"選擇 LLM 模型:\",\n",
    "            options=list(self.llm_models.keys()),\n",
    "            format_func=lambda x: self.llm_models[x],\n",
    "        )\n",
    "\n",
    "        embedding = st.sidebar.radio(\n",
    "            \"選擇 Embedding 模型:\",\n",
    "            options=list(self.embedding_models.keys()),\n",
    "            format_func=lambda x: self.embedding_models[x][\"name\"],\n",
    "        )\n",
    "\n",
    "        return llm, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278890da",
   "metadata": {},
   "source": [
    "### 處理 PDF 檔案並切割文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abf1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePDFProcessor:\n",
    "    \"\"\"處理 PDF 檔案並切割文字\"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def read_pdf(self, pdf_file):\n",
    "        \"\"\"讀取 PDF 並提取文字\"\"\"\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    def create_chunks(self, text, pdf_file):\n",
    "        \"\"\"將文字切成多個段落 (chunk)\"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "\n",
    "        while start < len(text):\n",
    "            end = start + self.chunk_size\n",
    "\n",
    "            if start > 0:\n",
    "                start = start - self.chunk_overlap\n",
    "\n",
    "            chunk = text[start:end]\n",
    "\n",
    "            if end < len(text):\n",
    "                last_period = chunk.rfind(\".\")\n",
    "                if last_period != -1:\n",
    "                    chunk = chunk[: last_period + 1]\n",
    "                    end = start + last_period + 1\n",
    "\n",
    "            chunks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": {\"source\": pdf_file.name},\n",
    "            })\n",
    "\n",
    "            start = end\n",
    "\n",
    "        return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77310ef9",
   "metadata": {},
   "source": [
    "### 簡單版 RAG 系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f511d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAGSystem:\n",
    "    \"\"\"簡單版 RAG 系統\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_model=\"openai\", llm_model=\"openai\"):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        # 初始化 ChromaDB\n",
    "        self.db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "        # 設定嵌入（Embedding）功能\n",
    "        self.setup_embedding_function()\n",
    "\n",
    "        # 設定 LLM\n",
    "        if llm_model == \"openai\":\n",
    "            self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        else:\n",
    "            self.llm = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "        # 建立或取得 collection\n",
    "        self.collection = self.setup_collection()\n",
    "\n",
    "    def setup_embedding_function(self):\n",
    "        \"\"\"依據設定選擇適合的嵌入方法\"\"\"\n",
    "        try:\n",
    "            if self.embedding_model == \"openai\":\n",
    "                self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                    model_name=\"text-embedding-3-small\",\n",
    "                )\n",
    "            elif self.embedding_model == \"nomic\":\n",
    "                self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=\"ollama\",\n",
    "                    api_base=\"http://localhost:11434/v1\",\n",
    "                    model_name=\"nomic-embed-text\",\n",
    "                )\n",
    "            else:\n",
    "                self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "        except Exception as e:\n",
    "            st.error(f\"設定嵌入函式錯誤: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def setup_collection(self):\n",
    "        \"\"\"建立或取得 ChromaDB collection\"\"\"\n",
    "        collection_name = f\"documents_{self.embedding_model}\"\n",
    "        try:\n",
    "            try:\n",
    "                collection = self.db.get_collection(\n",
    "                    name=collection_name, embedding_function=self.embedding_fn\n",
    "                )\n",
    "                st.info(f\"已使用現有的 collection ({self.embedding_model})\")\n",
    "            except:\n",
    "                collection = self.db.create_collection(\n",
    "                    name=collection_name,\n",
    "                    embedding_function=self.embedding_fn,\n",
    "                    metadata={\"model\": self.embedding_model},\n",
    "                )\n",
    "                st.success(f\"新建 collection 成功 ({self.embedding_model})\")\n",
    "            return collection\n",
    "        except Exception as e:\n",
    "            st.error(f\"建立 collection 出錯: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def add_documents(self, chunks):\n",
    "        \"\"\"將文字段落新增到資料庫\"\"\"\n",
    "        try:\n",
    "            if not self.collection:\n",
    "                self.collection = self.setup_collection()\n",
    "\n",
    "            self.collection.add(\n",
    "                ids=[chunk[\"id\"] for chunk in chunks],\n",
    "                documents=[chunk[\"text\"] for chunk in chunks],\n",
    "                metadatas=[chunk[\"metadata\"] for chunk in chunks],\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"新增文件時出錯: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def query_documents(self, query, n_results=3):\n",
    "        \"\"\"從資料庫查詢相關段落\"\"\"\n",
    "        try:\n",
    "            if not self.collection:\n",
    "                raise ValueError(\"找不到可用的 collection\")\n",
    "\n",
    "            results = self.collection.query(query_texts=[query], n_results=n_results)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            st.error(f\"查詢文件時出錯: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def generate_response(self, query, context):\n",
    "        \"\"\"用 LLM 根據 context 生成回答\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            根據以下內容回答問題。\n",
    "            如果內容中沒有答案，請直接說不知道。\n",
    "\n",
    "            內容: {context}\n",
    "\n",
    "            問題: {query}\n",
    "\n",
    "            答案:\n",
    "            \"\"\"\n",
    "\n",
    "            response = self.llm.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\" if self.llm_model == \"openai\" else \"llama3.2\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"你是一位樂於助人的助理。\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            st.error(f\"產生回答時出錯: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_embedding_info(self):\n",
    "        \"\"\"取得目前使用的嵌入模型資訊\"\"\"\n",
    "        model_selector = SimpleModelSelector()\n",
    "        model_info = model_selector.embedding_models[self.embedding_model]\n",
    "        return {\n",
    "            \"name\": model_info[\"name\"],\n",
    "            \"dimensions\": model_info[\"dimensions\"],\n",
    "            \"model\": self.embedding_model,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7441ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 21:54:20.424 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.585 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\33313\\.conda\\envs\\openai\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-17 21:54:20.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.587 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.title(\"🤖 簡單版 RAG 系統\")\n",
    "\n",
    "    # 初始化 Session 狀態\n",
    "    if \"processed_files\" not in st.session_state:\n",
    "        st.session_state.processed_files = set()\n",
    "    if \"current_embedding_model\" not in st.session_state:\n",
    "        st.session_state.current_embedding_model = None\n",
    "    if \"rag_system\" not in st.session_state:\n",
    "        st.session_state.rag_system = None\n",
    "\n",
    "    # 選擇模型\n",
    "    model_selector = SimpleModelSelector()\n",
    "    llm_model, embedding_model = model_selector.select_models()\n",
    "\n",
    "    # 如果嵌入模型改變，就清空資料\n",
    "    if embedding_model != st.session_state.current_embedding_model:\n",
    "        st.session_state.processed_files.clear()\n",
    "        st.session_state.current_embedding_model = embedding_model\n",
    "        st.session_state.rag_system = None\n",
    "        st.warning(\"嵌入模型已變更，請重新上傳文件\")\n",
    "\n",
    "    try:\n",
    "        if st.session_state.rag_system is None:\n",
    "            st.session_state.rag_system = SimpleRAGSystem(embedding_model, llm_model)\n",
    "\n",
    "        embedding_info = st.session_state.rag_system.get_embedding_info()\n",
    "        st.sidebar.info(\n",
    "            f\"目前使用模型:\\n\"\n",
    "            f\"- 名稱: {embedding_info['name']}\\n\"\n",
    "            f\"- 維度: {embedding_info['dimensions']}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        st.error(f\"初始化 RAG 系統時出錯: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # 上傳 PDF\n",
    "    pdf_file = st.file_uploader(\"上傳 PDF 文件\", type=\"pdf\")\n",
    "\n",
    "    if pdf_file and pdf_file.name not in st.session_state.processed_files:\n",
    "        processor = SimplePDFProcessor()\n",
    "        with st.spinner(\"處理 PDF 中...\"):\n",
    "            try:\n",
    "                text = processor.read_pdf(pdf_file)\n",
    "                chunks = processor.create_chunks(text, pdf_file)\n",
    "                if st.session_state.rag_system.add_documents(chunks):\n",
    "                    st.session_state.processed_files.add(pdf_file.name)\n",
    "                    st.success(f\"成功處理 {pdf_file.name}\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"處理 PDF 時出錯: {str(e)}\")\n",
    "\n",
    "    # 查詢介面\n",
    "    if st.session_state.processed_files:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"🔍 問問題\")\n",
    "        query = st.text_input(\"輸入問題:\")\n",
    "\n",
    "        if query:\n",
    "            with st.spinner(\"生成回答中...\"):\n",
    "                results = st.session_state.rag_system.query_documents(query)\n",
    "                if results and results[\"documents\"]:\n",
    "                    response = st.session_state.rag_system.generate_response(\n",
    "                        query, results[\"documents\"][0]\n",
    "                    )\n",
    "\n",
    "                    if response:\n",
    "                        st.markdown(\"### 📝 回答:\")\n",
    "                        st.write(response)\n",
    "\n",
    "                        with st.expander(\"查看來源段落\"):\n",
    "                            for idx, doc in enumerate(results[\"documents\"][0], 1):\n",
    "                                st.markdown(f\"**段落 {idx}:**\")\n",
    "                                st.info(doc)\n",
    "    else:\n",
    "        st.info(\"👆 請先上傳 PDF 文件\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
