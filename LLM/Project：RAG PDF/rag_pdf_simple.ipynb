{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719b9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (1.44.1)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (5.29.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\33313\\.conda\\envs\\openai\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9104f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n",
    "import uuid\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "\n",
    "# å¸¸æ•¸è¨­å®š\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0438ce",
   "metadata": {},
   "source": [
    "### ç°¡å–®çš„æ¨¡å‹é¸æ“‡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac7d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModelSelector:\n",
    "    \"\"\"ç°¡å–®çš„æ¨¡å‹é¸æ“‡å™¨\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # å¯é¸çš„ LLM æ¨¡å‹\n",
    "        self.llm_models = {\"openai\": \"GPT-4\", \"ollama\": \"Llama3\"}\n",
    "\n",
    "        # å¯é¸çš„ Embedding æ¨¡å‹åŠå…¶ç¶­åº¦\n",
    "        self.embedding_models = {\n",
    "            \"openai\": {\"name\": \"OpenAI Embeddings\", \"dimensions\": 1536, \"model_name\": \"text-embedding-3-small\"},\n",
    "            \"chroma\": {\"name\": \"Chroma Default\", \"dimensions\": 384, \"model_name\": None},\n",
    "            \"nomic\": {\"name\": \"Nomic Embed Text\", \"dimensions\": 768, \"model_name\": \"nomic-embed-text\"},\n",
    "        }\n",
    "\n",
    "    def select_models(self):\n",
    "        \"\"\"é€é Streamlit ä»‹é¢é¸æ“‡æ¨¡å‹\"\"\"\n",
    "        st.sidebar.title(\"ğŸ“š æ¨¡å‹é¸æ“‡\")\n",
    "\n",
    "        llm = st.sidebar.radio(\n",
    "            \"é¸æ“‡ LLM æ¨¡å‹:\",\n",
    "            options=list(self.llm_models.keys()),\n",
    "            format_func=lambda x: self.llm_models[x],\n",
    "        )\n",
    "\n",
    "        embedding = st.sidebar.radio(\n",
    "            \"é¸æ“‡ Embedding æ¨¡å‹:\",\n",
    "            options=list(self.embedding_models.keys()),\n",
    "            format_func=lambda x: self.embedding_models[x][\"name\"],\n",
    "        )\n",
    "\n",
    "        return llm, embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278890da",
   "metadata": {},
   "source": [
    "### è™•ç† PDF æª”æ¡ˆä¸¦åˆ‡å‰²æ–‡å­—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abf1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePDFProcessor:\n",
    "    \"\"\"è™•ç† PDF æª”æ¡ˆä¸¦åˆ‡å‰²æ–‡å­—\"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def read_pdf(self, pdf_file):\n",
    "        \"\"\"è®€å– PDF ä¸¦æå–æ–‡å­—\"\"\"\n",
    "        reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    def create_chunks(self, text, pdf_file):\n",
    "        \"\"\"å°‡æ–‡å­—åˆ‡æˆå¤šå€‹æ®µè½ (chunk)\"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "\n",
    "        while start < len(text):\n",
    "            end = start + self.chunk_size\n",
    "\n",
    "            if start > 0:\n",
    "                start = start - self.chunk_overlap\n",
    "\n",
    "            chunk = text[start:end]\n",
    "\n",
    "            if end < len(text):\n",
    "                last_period = chunk.rfind(\".\")\n",
    "                if last_period != -1:\n",
    "                    chunk = chunk[: last_period + 1]\n",
    "                    end = start + last_period + 1\n",
    "\n",
    "            chunks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"text\": chunk,\n",
    "                \"metadata\": {\"source\": pdf_file.name},\n",
    "            })\n",
    "\n",
    "            start = end\n",
    "\n",
    "        return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77310ef9",
   "metadata": {},
   "source": [
    "### ç°¡å–®ç‰ˆ RAG ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f511d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRAGSystem:\n",
    "    \"\"\"ç°¡å–®ç‰ˆ RAG ç³»çµ±\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_model=\"openai\", llm_model=\"openai\"):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        # åˆå§‹åŒ– ChromaDB\n",
    "        self.db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "        # è¨­å®šåµŒå…¥ï¼ˆEmbeddingï¼‰åŠŸèƒ½\n",
    "        self.setup_embedding_function()\n",
    "\n",
    "        # è¨­å®š LLM\n",
    "        if llm_model == \"openai\":\n",
    "            self.llm = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        else:\n",
    "            self.llm = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "        # å»ºç«‹æˆ–å–å¾— collection\n",
    "        self.collection = self.setup_collection()\n",
    "\n",
    "    def setup_embedding_function(self):\n",
    "        \"\"\"ä¾æ“šè¨­å®šé¸æ“‡é©åˆçš„åµŒå…¥æ–¹æ³•\"\"\"\n",
    "        try:\n",
    "            if self.embedding_model == \"openai\":\n",
    "                self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                    model_name=\"text-embedding-3-small\",\n",
    "                )\n",
    "            elif self.embedding_model == \"nomic\":\n",
    "                self.embedding_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=\"ollama\",\n",
    "                    api_base=\"http://localhost:11434/v1\",\n",
    "                    model_name=\"nomic-embed-text\",\n",
    "                )\n",
    "            else:\n",
    "                self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()\n",
    "        except Exception as e:\n",
    "            st.error(f\"è¨­å®šåµŒå…¥å‡½å¼éŒ¯èª¤: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def setup_collection(self):\n",
    "        \"\"\"å»ºç«‹æˆ–å–å¾— ChromaDB collection\"\"\"\n",
    "        collection_name = f\"documents_{self.embedding_model}\"\n",
    "        try:\n",
    "            try:\n",
    "                collection = self.db.get_collection(\n",
    "                    name=collection_name, embedding_function=self.embedding_fn\n",
    "                )\n",
    "                st.info(f\"å·²ä½¿ç”¨ç¾æœ‰çš„ collection ({self.embedding_model})\")\n",
    "            except:\n",
    "                collection = self.db.create_collection(\n",
    "                    name=collection_name,\n",
    "                    embedding_function=self.embedding_fn,\n",
    "                    metadata={\"model\": self.embedding_model},\n",
    "                )\n",
    "                st.success(f\"æ–°å»º collection æˆåŠŸ ({self.embedding_model})\")\n",
    "            return collection\n",
    "        except Exception as e:\n",
    "            st.error(f\"å»ºç«‹ collection å‡ºéŒ¯: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def add_documents(self, chunks):\n",
    "        \"\"\"å°‡æ–‡å­—æ®µè½æ–°å¢åˆ°è³‡æ–™åº«\"\"\"\n",
    "        try:\n",
    "            if not self.collection:\n",
    "                self.collection = self.setup_collection()\n",
    "\n",
    "            self.collection.add(\n",
    "                ids=[chunk[\"id\"] for chunk in chunks],\n",
    "                documents=[chunk[\"text\"] for chunk in chunks],\n",
    "                metadatas=[chunk[\"metadata\"] for chunk in chunks],\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            st.error(f\"æ–°å¢æ–‡ä»¶æ™‚å‡ºéŒ¯: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def query_documents(self, query, n_results=3):\n",
    "        \"\"\"å¾è³‡æ–™åº«æŸ¥è©¢ç›¸é—œæ®µè½\"\"\"\n",
    "        try:\n",
    "            if not self.collection:\n",
    "                raise ValueError(\"æ‰¾ä¸åˆ°å¯ç”¨çš„ collection\")\n",
    "\n",
    "            results = self.collection.query(query_texts=[query], n_results=n_results)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            st.error(f\"æŸ¥è©¢æ–‡ä»¶æ™‚å‡ºéŒ¯: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def generate_response(self, query, context):\n",
    "        \"\"\"ç”¨ LLM æ ¹æ“š context ç”Ÿæˆå›ç­”\"\"\"\n",
    "        try:\n",
    "            prompt = f\"\"\"\n",
    "            æ ¹æ“šä»¥ä¸‹å…§å®¹å›ç­”å•é¡Œã€‚\n",
    "            å¦‚æœå…§å®¹ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹ç›´æ¥èªªä¸çŸ¥é“ã€‚\n",
    "\n",
    "            å…§å®¹: {context}\n",
    "\n",
    "            å•é¡Œ: {query}\n",
    "\n",
    "            ç­”æ¡ˆ:\n",
    "            \"\"\"\n",
    "\n",
    "            response = self.llm.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\" if self.llm_model == \"openai\" else \"llama3.2\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½æ¨‚æ–¼åŠ©äººçš„åŠ©ç†ã€‚\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            st.error(f\"ç”¢ç”Ÿå›ç­”æ™‚å‡ºéŒ¯: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_embedding_info(self):\n",
    "        \"\"\"å–å¾—ç›®å‰ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹è³‡è¨Š\"\"\"\n",
    "        model_selector = SimpleModelSelector()\n",
    "        model_info = model_selector.embedding_models[self.embedding_model]\n",
    "        return {\n",
    "            \"name\": model_info[\"name\"],\n",
    "            \"dimensions\": model_info[\"dimensions\"],\n",
    "            \"model\": self.embedding_model,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7441ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 21:54:20.424 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.585 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\33313\\.conda\\envs\\openai\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-17 21:54:20.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.587 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.587 Session state does not function when running a script without `streamlit run`\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.590 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.592 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:20.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-17 21:54:21.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.title(\"ğŸ¤– ç°¡å–®ç‰ˆ RAG ç³»çµ±\")\n",
    "\n",
    "    # åˆå§‹åŒ– Session ç‹€æ…‹\n",
    "    if \"processed_files\" not in st.session_state:\n",
    "        st.session_state.processed_files = set()\n",
    "    if \"current_embedding_model\" not in st.session_state:\n",
    "        st.session_state.current_embedding_model = None\n",
    "    if \"rag_system\" not in st.session_state:\n",
    "        st.session_state.rag_system = None\n",
    "\n",
    "    # é¸æ“‡æ¨¡å‹\n",
    "    model_selector = SimpleModelSelector()\n",
    "    llm_model, embedding_model = model_selector.select_models()\n",
    "\n",
    "    # å¦‚æœåµŒå…¥æ¨¡å‹æ”¹è®Šï¼Œå°±æ¸…ç©ºè³‡æ–™\n",
    "    if embedding_model != st.session_state.current_embedding_model:\n",
    "        st.session_state.processed_files.clear()\n",
    "        st.session_state.current_embedding_model = embedding_model\n",
    "        st.session_state.rag_system = None\n",
    "        st.warning(\"åµŒå…¥æ¨¡å‹å·²è®Šæ›´ï¼Œè«‹é‡æ–°ä¸Šå‚³æ–‡ä»¶\")\n",
    "\n",
    "    try:\n",
    "        if st.session_state.rag_system is None:\n",
    "            st.session_state.rag_system = SimpleRAGSystem(embedding_model, llm_model)\n",
    "\n",
    "        embedding_info = st.session_state.rag_system.get_embedding_info()\n",
    "        st.sidebar.info(\n",
    "            f\"ç›®å‰ä½¿ç”¨æ¨¡å‹:\\n\"\n",
    "            f\"- åç¨±: {embedding_info['name']}\\n\"\n",
    "            f\"- ç¶­åº¦: {embedding_info['dimensions']}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        st.error(f\"åˆå§‹åŒ– RAG ç³»çµ±æ™‚å‡ºéŒ¯: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # ä¸Šå‚³ PDF\n",
    "    pdf_file = st.file_uploader(\"ä¸Šå‚³ PDF æ–‡ä»¶\", type=\"pdf\")\n",
    "\n",
    "    if pdf_file and pdf_file.name not in st.session_state.processed_files:\n",
    "        processor = SimplePDFProcessor()\n",
    "        with st.spinner(\"è™•ç† PDF ä¸­...\"):\n",
    "            try:\n",
    "                text = processor.read_pdf(pdf_file)\n",
    "                chunks = processor.create_chunks(text, pdf_file)\n",
    "                if st.session_state.rag_system.add_documents(chunks):\n",
    "                    st.session_state.processed_files.add(pdf_file.name)\n",
    "                    st.success(f\"æˆåŠŸè™•ç† {pdf_file.name}\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"è™•ç† PDF æ™‚å‡ºéŒ¯: {str(e)}\")\n",
    "\n",
    "    # æŸ¥è©¢ä»‹é¢\n",
    "    if st.session_state.processed_files:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"ğŸ” å•å•é¡Œ\")\n",
    "        query = st.text_input(\"è¼¸å…¥å•é¡Œ:\")\n",
    "\n",
    "        if query:\n",
    "            with st.spinner(\"ç”Ÿæˆå›ç­”ä¸­...\"):\n",
    "                results = st.session_state.rag_system.query_documents(query)\n",
    "                if results and results[\"documents\"]:\n",
    "                    response = st.session_state.rag_system.generate_response(\n",
    "                        query, results[\"documents\"][0]\n",
    "                    )\n",
    "\n",
    "                    if response:\n",
    "                        st.markdown(\"### ğŸ“ å›ç­”:\")\n",
    "                        st.write(response)\n",
    "\n",
    "                        with st.expander(\"æŸ¥çœ‹ä¾†æºæ®µè½\"):\n",
    "                            for idx, doc in enumerate(results[\"documents\"][0], 1):\n",
    "                                st.markdown(f\"**æ®µè½ {idx}:**\")\n",
    "                                st.info(doc)\n",
    "    else:\n",
    "        st.info(\"ğŸ‘† è«‹å…ˆä¸Šå‚³ PDF æ–‡ä»¶\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
