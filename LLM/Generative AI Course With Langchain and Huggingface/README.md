## NLP

-   Tokenization：Tokenization 是 NLP 中的一個重要步驟，用於將一段文字分解為較小的單元（稱為 Tokens）。
-

## Tokenization

-   安裝 nltk：pip install nltk
-
