{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 確認是否有可用的 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 針對train set 進行數據增強和正規化\n",
    "train_transform = transforms.Compose([ # 將所有轉換操作依次應用到每張圖片\n",
    "    transforms.Resize((64, 64)), # 調整圖片大小\n",
    "    transforms.RandomHorizontalFlip(), # 隨機水平翻轉圖片-> 增強資料多樣性，模擬可能出現的視覺變化\n",
    "    transforms.RandomRotation(20), # 將圖片隨機旋轉 -> 增加資料的旋轉不變性\n",
    "    transforms.RandomResizedCrop(64), # 機裁剪圖片的某個區域，並調整到64x64\n",
    "    transforms.ToTensor(), # PIL圖片格式轉換為tensor\n",
    "    # 資料[0, 255]正規化為[0.0, 1.0]\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5], \n",
    "        std=[0.5, 0.5, 0.5]\n",
    "        ) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 針對test set 進行正規化\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\"D:/Downloads/dataset/training_set\", transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(\"D:/Downloads/dataset/test_set\", transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料載入器\n",
    "# shuffle 控制是否隨機打亂數據集\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "類別: ['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "print(f\"類別: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) # 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # 二元交叉熵損失函數\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.6789, Accuracy: 0.5647\n",
      "Epoch 2/25, Loss: 0.6457, Accuracy: 0.6278\n",
      "Epoch 3/25, Loss: 0.6316, Accuracy: 0.6400\n",
      "Epoch 4/25, Loss: 0.6216, Accuracy: 0.6418\n",
      "Epoch 5/25, Loss: 0.6134, Accuracy: 0.6616\n",
      "Epoch 6/25, Loss: 0.6117, Accuracy: 0.6573\n",
      "Epoch 7/25, Loss: 0.6069, Accuracy: 0.6679\n",
      "Epoch 8/25, Loss: 0.6012, Accuracy: 0.6729\n",
      "Epoch 9/25, Loss: 0.5940, Accuracy: 0.6760\n",
      "Epoch 10/25, Loss: 0.5938, Accuracy: 0.6734\n",
      "Epoch 11/25, Loss: 0.5937, Accuracy: 0.6833\n",
      "Epoch 12/25, Loss: 0.5897, Accuracy: 0.6786\n",
      "Epoch 13/25, Loss: 0.5952, Accuracy: 0.6736\n",
      "Epoch 14/25, Loss: 0.5865, Accuracy: 0.6807\n",
      "Epoch 15/25, Loss: 0.5841, Accuracy: 0.6874\n",
      "Epoch 16/25, Loss: 0.5817, Accuracy: 0.6875\n",
      "Epoch 17/25, Loss: 0.5771, Accuracy: 0.6916\n",
      "Epoch 18/25, Loss: 0.5825, Accuracy: 0.6915\n",
      "Epoch 19/25, Loss: 0.5747, Accuracy: 0.6957\n",
      "Epoch 20/25, Loss: 0.5769, Accuracy: 0.6930\n",
      "Epoch 21/25, Loss: 0.5733, Accuracy: 0.6997\n",
      "Epoch 22/25, Loss: 0.5662, Accuracy: 0.7014\n",
      "Epoch 23/25, Loss: 0.5657, Accuracy: 0.7007\n",
      "Epoch 24/25, Loss: 0.5663, Accuracy: 0.6986\n",
      "Epoch 25/25, Loss: 0.5620, Accuracy: 0.7031\n"
     ]
    }
   ],
   "source": [
    "# 訓練循環\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 前向傳播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "        # 反向傳播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 計算精確度\n",
    "        predictions = (outputs.squeeze() > 0.5).float()  # 二元分類（假設輸出是概率）\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    # 計算平均損失和精確度\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
