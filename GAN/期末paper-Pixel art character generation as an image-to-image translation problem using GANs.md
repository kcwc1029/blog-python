
## 1. Abstract

å•é¡ŒèƒŒæ™¯ï¼šPixel art ä¸­çš„è§’è‰²è¨­è¨ˆéœ€è¦å¤§é‡åè¦†é‹ç®—ï¼Œä¿®æ”¹ä¸€å€‹è§’åº¦æœƒå½±éŸ¿å…¶ä»–è§’åº¦ã€‚
æ ¸å¿ƒä»»å‹™ï¼šFramed as an image-to-image translation taskï¼š
- e.g., generating a sprite facing right from one facing front.
æ–¹æ³•æ¶æ§‹ï¼šBuild on Pix2Pixâ€™s GAN architecture, leveraging characteristics of pixel art.
è³‡æ–™é›†ï¼šUsed both small datasets (<1k) and a large one (12k).
è²¢ç»ï¼šWe hypothesize that the problem of generating character sprites in a target pose (e.g., facing right) given a source (e.g., facing front) can be framed as an image-to-image translation task
- æå‡ºäº†ä¸€å€‹ mixed-initiative sprite editor è®“äººé¡èˆ‡æ¨¡å‹å…±å‰µè§’è‰²åœ–ã€‚
- ä½¿ç”¨ GAN è™•ç†ã€Œè§’è‰²ä¸åŒè¦–è§’ç”Ÿæˆã€å•é¡Œã€‚


![[image.png]]

## 2. æ–‡ç»æ¢è¨ï¼šImage-to-Image Translation
### 2.1. ä»€éº¼æ˜¯ image-to-image translation
> Pang et al. [11] define image-to-image translation as the process of converting an input image ğ‘¥ğ´ in a source domain ğ´ to a target domain ğµ while keeping some intrinsic content from ğ´ and transferring it to the extrinsic style of ğµ

å®šç¾©ï¼šæŠŠæŸå¼µåœ–ï¼ˆä¾†æºé ˜åŸŸAï¼‰è½‰æˆå¦ä¸€å¼µåœ–ï¼ˆç›®æ¨™é ˜åŸŸBï¼‰
- åŒæ™‚ä¿ç•™åŸåœ–çš„å…§åœ¨å…§å®¹ï¼ˆintrinsic contentï¼‰
- ä¸¦æ‡‰ç”¨æ–°åœ–çš„å¤–åœ¨é¢¨æ ¼ï¼ˆextrinsic styleï¼‰




- åœ¨é€™ç¯‡è«–æ–‡ä¸­ï¼Œç ”ç©¶è€…å°‡ã€Œè§’è‰²ä¸åŒè¦–è§’ï¼ˆæ­£é¢ã€å´é¢ã€èƒŒé¢ç­‰ï¼‰ã€è¦–ç‚ºä¸åŒçš„ã€Œdomainï¼ˆé ˜åŸŸï¼‰ã€ã€‚
-

### 2.2. å…§åœ¨å…§å®¹ vs. å¤–åœ¨é¢¨æ ¼

> The intrinsic content of the source domain is the character phenotype features, accessories, and palette, while the extrinsic style of the target domain comprises the arrangement of pixels in the new pose.

> In this work, we frame the approached problem as an image-to-image translation task, with the domains representing different character poses: front, right, back, and left.

- å…§åœ¨å…§å®¹ï¼ˆintrinsic contentï¼‰ï¼šè§’è‰²çš„åŸºæœ¬ç‰¹å¾µ
	- å¦‚ï¼šé«®å‹ã€è¡£æœã€é…ä»¶ã€é¡è‰²ï¼ˆpaletteï¼‰
- å¤–åœ¨é¢¨æ ¼ï¼ˆextrinsic styleï¼‰ï¼šè§’è‰²çš„æ–°å§¿å‹¢ä¸‹ï¼Œåƒç´ å¦‚ä½•æ’åˆ—

### 2.3. Pix2Pix

> An influential work on image-to-image translation is Pix2Pix

> It is a general architecture of deep generative models that proposes to condition the generation process on an image in the source domain while doing supervised training for the generator to create its version in a target domain.

- Pix2Pix æ˜¯å½±åƒè½‰å½±åƒï¼ˆimage-to-image translationï¼‰é ˜åŸŸä¸­çš„ä»£è¡¨æ€§æ¨¡å‹ã€‚
- Pix2Pix æ˜¯ä¸€ç¨®æ¢ä»¶å¼ç”Ÿæˆæ¨¡å‹ï¼ˆconditional GANï¼‰ã€‚
- å±¬æ–¼æœ‰ç›£ç£å­¸ç¿’ï¼ˆsupervised learningï¼‰ï¼Œå› ç‚ºè¨“ç·´æ™‚æœ‰æˆå°è³‡æ–™ã€‚
- å®ƒçš„ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰æœƒæ ¹æ“šè¼¸å…¥åœ–ç‰‡ï¼ˆsource domainï¼‰ç”¢ç”Ÿå°æ‡‰çš„è¼¸å‡ºåœ–ï¼ˆtarget domainï¼‰ã€‚
	- Generatorï¼šä½¿ç”¨ U-Net çµæ§‹ï¼Œä¿ç•™ç´°ç¯€èˆ‡åœ–åƒçµæ§‹ã€‚è¼¸å…¥èˆ‡è¼¸å‡ºåœ–ç‰‡è§£æåº¦ç›¸åŒï¼Œä½†é¢¨æ ¼/å…§å®¹ä¸åŒã€‚
	- Discriminatorï¼ˆé‘‘åˆ¥å™¨ï¼‰ï¼š
		- ä¸åªåˆ¤æ–·æ•´å¼µåœ–çœŸå‡ï¼Œè€Œæ˜¯å°åœ–ä¸­çš„æ¯å€‹å°å€å¡Šï¼ˆpatchï¼‰åšåˆ¤åˆ¥ã€‚
		- æœ‰åŠ©æ–¼å­¸ç¿’å±€éƒ¨ç´°ç¯€ï¼Œå°¤å…¶é©åˆåƒ pixel art é€™ç¨®æ¯å€‹åƒç´ éƒ½å¾ˆé‡è¦çš„åœ–åƒã€‚
- æ‡‰ç”¨ï¼š Pix2Pix å¯æ‡‰ç”¨æ–¼å„ç¨®åœ–åƒå°æ‡‰ä»»å‹™
	- ç™½å¤©ç…§ç‰‡ â†” å¤œé–“ç…§ç‰‡
	- é»‘ç™½åœ– â†” å½©è‰²åœ–
	- å€åŸŸæ¨™è¨˜åœ– â†” å¯¦æ™¯ç…§ç‰‡

### 2.4. å…ˆå‰ç ”ç©¶
> Translate line art sketches of characters into a grayscale and a colored sprite [...] 85 and 530 examples.â€

- Serpa & Rodrigues (2019)åˆ©ç”¨ Pix2Pix å°‡è§’è‰²ç·šç¨¿è½‰æˆç°éšèˆ‡å½©è‰² spriteã€‚
	- æˆæ•ˆï¼šç°éšåœ–æ•ˆæœå¥½ï¼Œå½©è‰²åœ–æœ‰å¾ˆå¤šé«˜é »é›œè¨Šï¼Œç‰¹åˆ¥æ˜¯åœ¨æ²’çœ‹éçš„å§¿å‹¢ï¼ˆunseen posesï¼‰
	- å•é¡Œï¼šè¨“ç·´è³‡æ–™å¤ªå°‘ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®

> Adapted Pix2Pix [...] grayscale to colored images [...] YUV inputs yielded better results than RGB.

- Jiang & Sweetser (2021)åˆ©ç”¨ Pix2Pixå°‡é»‘ç™½åœ–æ¸²æŸ“æˆå½©è‰²åœ–(é€™ä¹Ÿæ˜¯æˆ‘å€‘æƒ³è¦å®Œæˆçš„æœŸæœ«å°ˆæ¡ˆ)
	- ä½¿ç”¨ YUV è‰²å½©ç©ºé–“ï¼ˆè€Œä¸æ˜¯ RGBï¼‰
	- å› ç‚ºåªéœ€è¦å­¸ UVï¼ˆè‰²å½©ï¼‰ï¼ŒYï¼ˆäº®åº¦ï¼‰å¯è¦–ç‚ºæ¢ä»¶åƒè€ƒå€¼ã€‚

> Proposed a CVAE to transfer the domain of a PokÃ©mon [...] blurry results with noisy colors

- Gonzalez et al. (2020)ä½¿ç”¨ CVAEï¼ˆè®Šåˆ†è‡ªç·¨ç¢¼å™¨ï¼‰å°‡ PokÃ©mon åœ–å¾ä¸€ç¨®é¡å‹ï¼ˆå¦‚ç«ï¼‰è½‰ç‚ºå¦ä¸€ç¨®ï¼ˆå¦‚è‰ï¼‰ã€‚
	- å•é¡Œ01ï¼šçµæœæ¨¡ç³Šã€ä¸ç²¾ç¢ºï¼Œé¡è‰²äº‚ã€é‚Šç·£ä¸æ¸…
	- å•é¡Œ02ï¼šåŸå› ä¹‹ä¸€æ˜¯è³‡æ–™é‡å¤ªå°ï¼ˆ974 å¼µåœ–ï¼‰
> Proposed a multiple discriminators GAN ... trained with bone-graph pose image and a color-shape image

-  Hong et al. (2019) ä½¿ç”¨å…©å€‹é‘‘åˆ¥å™¨çš„ GANï¼ˆMDGANï¼‰
	- ä¸€å€‹åˆ¤æ–·ã€Œå½¢ç‹€+é¡è‰²æ˜¯å¦æ­£ç¢ºã€
	- ä¸€å€‹åˆ¤æ–·ã€Œå§¿å‹¢æ˜¯å¦èˆ‡éª¨æ¶åœ–åŒ¹é…ã€
	- é™åˆ¶01ï¼šéœ€è¦é¡å¤–çš„éª¨æ¶åœ–ï¼ˆbone-graphï¼‰ï¼Œè³‡æ–™è£½ä½œæˆæœ¬é«˜
	- é™åˆ¶02ï¼šåƒ…é©ç”¨ã€Œç›¸åŒå½¢ç‹€è§’è‰²ã€â†’ é™åˆ¶å‰µä½œå¤šæ¨£æ€§

### 2.5. æœ¬ç ”ç©¶çš„å·®ç•°èˆ‡è²¢ç»ï¼ˆèˆ‡ä¸Šè¿°ç›¸æ¯”ï¼‰

> Our work also adapts Pix2Pix [...] But differently from the aforementioned works [...]

| æ¯”è¼ƒé …ç›®      | æœ¬ç ”ç©¶çš„å„ªå‹¢                   |
| --------- | ------------------------ |
| æ˜¯å¦é™åˆ¶è§’è‰²å½¢ç‹€  | âŒ ä¸é™åˆ¶ï¼Œæ”¯æ´ä¸åŒè§’è‰²æ¨£è²Œ           |
| æ˜¯å¦éœ€è¦éª¨æ¶è³‡æ–™é›† | âŒ ä¸éœ€è¦äººå·¥éª¨æ¶ï¼ˆèˆ‡ MDGAN ä¸åŒï¼‰    |
| è‰²å½©ç©ºé–“é¸æ“‡    | âœ… ä½¿ç”¨ RGBAï¼ˆæ¯” RGB æ›´ä¿ç•™é€æ˜è³‡è¨Šï¼‰ |
| ä»»å‹™ç›®æ¨™      | âœ… å°ˆæ³¨æ–¼ä¸åŒã€Œè¦–è§’ã€çš„è½‰æ›ï¼ˆæ­£é¢ â†’ å´é¢ï¼‰  |
| æ¨¡å‹æ³›åŒ–èƒ½åŠ›    | âœ… æ¢è¨å¤šæ¨£è³‡æ–™é›†å¦‚ä½•å½±éŸ¿ç”Ÿæˆå“è³ª        |



## 3. æ–‡ç»æ¢è¨ï¼šGenerating pixel art


![[image-2.png]]

### 3.1. è§£æåº¦ä½ â†’ æ¯å€‹åƒç´ éƒ½è¶…é‡è¦

>Pixel art images frequently have a lower resolution, so each pixel encodes more information.

> A one-pixel difference in a characterâ€™s face can change its expressionã€€

 - pixel art çš„è§£æåº¦å¾ˆä½ï¼ˆé€šå¸¸æ˜¯ 32x32 æˆ– 64x64ï¼‰ï¼Œ
	- æ¯ä¸€å€‹åƒç´ éƒ½ä»£è¡¨é‡è¦çš„è¦–è¦ºè³‡è¨Šï¼
	- ä¸€å€‹åƒç´ æ”¹è®Š â†’ å°±å¯èƒ½è®“è§’è‰²è¡¨æƒ…å®Œå…¨ä¸åŒã€‚

### 3.2. é »ç‡åˆ†å¸ƒèˆ‡ç…§ç‰‡ä¸åŒ

> The distribution of frequencies along the image is also different [...] low-frequency regions interleave more quickly with high-frequency parts

- ç›¸æ¯”ç…§ç‰‡ï¼Œpixel arté¡è‰²å€å¡Šï¼ˆä½é »ï¼‰èˆ‡é‚Šç·£è®ŠåŒ–ï¼ˆé«˜é »ï¼‰äº¤éŒ¯å¾—æ›´å¯†é›†
	- åœ–ç‰‡å° â†’ è‰²å¡Šèˆ‡é‚Šç•Œæ›´è¿‘

### 3.3. èª¿è‰²é™åˆ¶å¸¶ä¾†ç¨ç‰¹æŠ€å·§
> Pixel artists compose images by selecting colors from a small palette, frequently with less than thirty colors

- pixel art å¸¸åªç”¨ 30 ç¨®é¡è‰²ä»¥ä¸‹ï¼Œå› æ­¤ç™¼å±•å‡ºä¸€äº›å°ˆé–€æŠ€è¡“ï¼š
	- Color rampsï¼šç”¨å°‘é‡é¡è‰²è¡¨ç¾æ¼¸å±¤æ•ˆæœ
	- Ditheringï¼šæŠŠå…©ç¨®é¡è‰²äº¤éŒ¯æ’åˆ—ä¾†æ··è‰²ï¼Œå½¢æˆè¦–è¦ºæ··åˆ

### 3.4. pixel art è³‡æ–™é›†æ¯”è¼ƒå°‘
> Pixel art datasets are much more scarce than photography-based ones.
-  èˆ‡çœŸå¯¦ç…§ç‰‡ç›¸æ¯”ï¼Œpixel art çš„è¨“ç·´è³‡æ–™é›†å¾ˆç¨€å°‘ã€å¾ˆé›£æ‰¾ã€‚

## 4. æ–‡ç»æ¢è¨ï¼šMixed-initiative content generationï¼ˆæ··åˆä¸»å‹•å…§å®¹ç”Ÿæˆï¼‰

### 4.1. ä»€éº¼æ˜¯ Mixed-Initiative
> Some procedural content generation methods are fully automated, others involve more human interaction [...] automate only part of the process

> Task initiative, speaker initiative, outcome initiative

> An iterative loop where at least one agent [...] can take the initiative [...] all involved agents [...] can contribute [...] and respond at least once

- äººèˆ‡ AIä¸€èµ·å…§å®¹ç”Ÿæˆï¼ˆåƒæ˜¯éŠæˆ²è§’è‰²ã€é—œå¡ã€ç¾è¡“ç´ æç­‰ï¼‰
- Liapis et al.ï¼ˆ2016ï¼‰å®šç¾©çš„ä¸‰ç¨®ã€Œä¸»å‹•æ€§ã€
	- åœ¨é€™ç¨®ç³»çµ±ä¸­ï¼Œäººå’Œ AI éƒ½å¯ä»¥ã€Œä¸»å‹•ã€åšäº‹ï¼ŒåŒ…æ‹¬
	- Task initiativeï¼šèª°å®šç¾©å·¥ä½œè¦åšä»€éº¼ï¼Ÿ
	- Speaker initiativeï¼šèª°æ±ºå®šä½•æ™‚é–‹å§‹åšï¼Ÿ
	- Outcome initiativeï¼šèª°ä¾†æ±ºå®šæ€éº¼åšæœ€å¥½ï¼Ÿ

- Lai et al.ï¼ˆ2022ï¼‰å° Mixed-Initiative çš„åš´æ ¼å®šç¾©
	- è‡³å°‘æœ‰ä¸€å€‹åƒèˆ‡è€…å¯ä»¥ã€Œä¸»å‹•ç™¼èµ·ã€å‰µä½œ
	- äººèˆ‡ AI éƒ½è¦èƒ½ã€Œå°å…§å®¹åšå‡ºè²¢ç»ã€
	-  æ¯å€‹åƒèˆ‡è€…éƒ½è¦ã€Œè‡³å°‘äº’å‹•ä¸€æ¬¡ã€


### 4.2. å…ˆå‰ç ”ç©¶

> A mixed-initiative drawing tool that gives human agents direct control over the initial specification of drawings and indirect over their interactive evolution conducted by a computational agent

- Zhang et al. (2015) â€“ DrawCompileEvolve
	- ä½¿ç”¨è€…ç•«å‡ºåˆç¨¿ï¼ˆç›´æ¥æ§åˆ¶ï¼‰
	- AI æ¥æ‰‹æ¼”åŒ–åœ–åƒï¼ˆé–“æ¥æ§åˆ¶ï¼‰
	- äººèˆ‡é›»è…¦äº¤æ›¿åƒèˆ‡ â†’ ç‚ºå‰µä½œæä¾›æ–°è®ŠåŒ–

> The computational agent offers a sketch that should inspire them [...] conceptual shift (e.g., a plane as inspiration for a chair).

- Karimi et al. (2019)
	- äººç•«è‰åœ– â†’ AI çµ¦å‡ºéˆæ„Ÿè‰åœ–ï¼ˆå¯ä»¥å¾ˆè·³ toneï¼‰
	- AI ä½¿ç”¨ã€Œæ¦‚å¿µè½‰æ›ï¼ˆconceptual shiftï¼‰ã€ä¾†å•Ÿç™¼äººé¡å‰µé€ åŠ›
	- ä¾‹å¦‚ï¼šç•«é£›æ©Ÿ â†’ AI çµ¦å‡ºæ¤…å­çš„è‰åœ– â†’ æé«˜å‰µæ„è¡¨ç¾

> Design the computational agent to help the users in their tasks [...] receive completion suggestions using a text prompt.

- Ibarrola et al. (2022)
	- ä½¿ç”¨è€…è¼¸å…¥æç¤ºæ–‡å­—ï¼ˆtext promptï¼‰
	- AI çµ¦å‡ºå®Œæˆå»ºè­°ï¼ˆè£œå…¨åœ–åƒï¼‰
	- ç›®æ¨™æ˜¯è®“ AI è¼”åŠ©è€Œéä¸»å°å‰µä½œ

> We created a sprite editor [...] allows a human agent to generate images procedurally

- æœ¬ç ”ç©¶
	- ä½¿ç”¨è€…ç•«è§’è‰²æ­£é¢ â†’ æ‹–é€²ç·¨è¼¯å™¨ â†’ AI å¹«ä½ ç”Ÿå‡ºå´é¢ã€èƒŒé¢
	- å¯ å¿«é€Ÿäº¤äº’ã€ä¸å—é™åˆ¶ç·¨è¼¯ã€äººæ©Ÿå¯ä»¥åè¦†äº’å‹•
	- æ¯æ¬¡äº’å‹•éƒ½æ˜¯ä¸€æ¬¡ã€Œç”Ÿæˆ â†’ ç·¨è¼¯ â†’ å†ç”Ÿæˆã€çš„å¾ªç’°


## 5. åˆ†å·¥ç’°ç¯€

paperï¼šhttps://reurl.cc/VYgr7N

A çµ„å“¡ï¼šè² è²¬èƒŒæ™¯èˆ‡æ¯”è¼ƒç ”ç©¶ï¼ˆæ–‡ç»å°å‘ï¼Œè¼ƒè¼•ï¼‰
- ä»»å‹™æ€§è³ªï¼šèƒŒæ™¯é‹ªé™³èˆ‡è„ˆçµ¡æ•´ç†ï¼Œå¼·èª¿æ¸…æ¥šè„ˆçµ¡èˆ‡æ ¸å¿ƒå·®ç•°
- Section 1. Introduction
- Section 2. Related Work

B çµ„å“¡ï¼šæ¨¡å‹æ¶æ§‹è§£é‡‹
- ä»»å‹™æ€§è³ªï¼šæŠ€è¡“ç´°ç¯€ï¼‹ç¶²è·¯æ¶æ§‹ç†è§£ï¼Œå»ºè­°ç”¨åœ–è¼”åŠ©èªªæ˜
- Section 3. Architecture Overview

C çµ„å“¡ï¼šè¨“ç·´èˆ‡å¯¦é©—æ–¹æ³•
- ä»»å‹™æ€§è³ªï¼šèªªæ˜å¦‚ä½•é©—è­‰æ¨¡å‹èˆ‡å¯¦é©—åˆ†æï¼Œå»ºè­°ä»¥åœ–è¡¨ã€ç¯„ä¾‹è¼”åŠ©ã€‚
- Section 4. Experiments
- Section 5. Results

D çµ„å“¡ï¼šæ‡‰ç”¨èˆ‡æœªä¾†å±•æœ›
- ä»»å‹™æ€§è³ªï¼šåæ‡‰ç”¨é¢ï¼Œé©åˆæ“…é•·è¦–è¦ºæˆ–äº’å‹•è§£èªªçš„çµ„å“¡ã€‚
- Section 6. Evaluation with All Sides
- Section 7. Sprite Editor 
- Section 8. Final Remarks


ç¬¬Hçµ„ï¼šé™³ä¿¡å˜‰ã€æœ±æ™‰è³¢ã€é™³äº­éœ“ã€é™³ç¶­èª 